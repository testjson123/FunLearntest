{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train funLearn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras.layers import (Activation, BatchNormalization, Conv2D, Dense,\n",
    "                          Dropout, Flatten, MaxPooling2D)\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Python version\n3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version\")\n",
    "print (sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.8.3\n"
     ]
    }
   ],
   "source": [
    "print(tfjs.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH=224\n",
    "IMG_HEIGHT=224\n",
    "img_folder=r'C:/Users/younis3/Desktop/train_intel/animals-archive/seg_train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define constants\n",
    "IMG_HEIGHT = 80\n",
    "IMG_WIDTH  = 80\n",
    "CHANNELS   = 3\n",
    "batch_size = 4\n",
    "\n",
    "#train_path = 'C:/Users/younis3/Desktop/train_intel/archive/seg_train/seg_train/'\n",
    "#test_path  = 'C:/Users/younis3/Desktop/train_intel/archive/seg_test/seg_test/'\n",
    "#class_names = ['cat', 'chicken', 'duck', 'sheep', 'k','kk']\n",
    "\n",
    "train_path = 'C:/Users/younis3/Desktop/train_intel/animals-archive/seg_train/'\n",
    "test_path  = 'C:/Users/younis3/Desktop/train_intel/animals-archive/seg_test/'\n",
    "class_names = ['cat', 'chicken', 'duck', 'sheep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 72 images belonging to 4 classes.\nFound 8 images belonging to 4 classes.\nFound 20 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "## Generators ##\n",
    " \n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "# Training\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size = (IMG_HEIGHT, IMG_WIDTH),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Validation\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Evaluation\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_47\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_174 (Conv2D)          (None, 78, 78, 32)        896       \n_________________________________________________________________\nbatch_normalization_173 (Bat (None, 78, 78, 32)        128       \n_________________________________________________________________\nactivation_173 (Activation)  (None, 78, 78, 32)        0         \n_________________________________________________________________\nmax_pooling2d_173 (MaxPoolin (None, 39, 39, 32)        0         \n_________________________________________________________________\nconv2d_175 (Conv2D)          (None, 37, 37, 32)        9248      \n_________________________________________________________________\nbatch_normalization_174 (Bat (None, 37, 37, 32)        128       \n_________________________________________________________________\nactivation_174 (Activation)  (None, 37, 37, 32)        0         \n_________________________________________________________________\nmax_pooling2d_174 (MaxPoolin (None, 19, 19, 32)        0         \n_________________________________________________________________\nconv2d_176 (Conv2D)          (None, 17, 17, 64)        18496     \n_________________________________________________________________\nbatch_normalization_175 (Bat (None, 17, 17, 64)        256       \n_________________________________________________________________\nactivation_175 (Activation)  (None, 17, 17, 64)        0         \n_________________________________________________________________\nmax_pooling2d_175 (MaxPoolin (None, 9, 9, 64)          0         \n_________________________________________________________________\nconv2d_177 (Conv2D)          (None, 7, 7, 128)         73856     \n_________________________________________________________________\nbatch_normalization_176 (Bat (None, 7, 7, 128)         512       \n_________________________________________________________________\nactivation_176 (Activation)  (None, 7, 7, 128)         0         \n_________________________________________________________________\nmax_pooling2d_176 (MaxPoolin (None, 4, 4, 128)         0         \n_________________________________________________________________\nflatten_46 (Flatten)         (None, 2048)              0         \n_________________________________________________________________\ndense_47 (Dense)             (None, 4)                 8196      \n=================================================================\nTotal params: 111,716\nTrainable params: 111,204\nNon-trainable params: 512\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), input_shape=(IMG_HEIGHT, IMG_WIDTH, CHANNELS)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2,2, padding='same'))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2,2, padding='same'))\n",
    "\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2,2, padding='same'))\n",
    "\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(2,2, padding='same'))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callbacks\n",
    "# early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "# lr_redux = ReduceLROnPlateau(monitor='val_loss',\n",
    "#                             patience = 3, verbose = 1,\n",
    "#                             factor = 0.1, min_lr = 0.000001)\n",
    "\n",
    "# log_dir = f\"/home/tasos/logs/{int(time.time())}\"\n",
    "\n",
    "# tensorboard = TensorBoard(log_dir=log_dir)\n",
    "# callbacks = [early_stop, lr_redux, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 2s 129ms/step - loss: 1.4060 - accuracy: 0.4875 - val_loss: 1.3710 - val_accuracy: 0.2500\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 0.9961 - accuracy: 0.5414 - val_loss: 1.3523 - val_accuracy: 0.6250\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.5972 - accuracy: 0.7986 - val_loss: 1.3858 - val_accuracy: 0.2500\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.3362 - accuracy: 0.8544 - val_loss: 1.4750 - val_accuracy: 0.2500\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.2914 - accuracy: 0.9334 - val_loss: 1.5953 - val_accuracy: 0.2500\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 0.2193 - accuracy: 0.9738 - val_loss: 1.7134 - val_accuracy: 0.2500\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.0820 - accuracy: 0.9862 - val_loss: 1.7226 - val_accuracy: 0.2500\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.2310 - accuracy: 0.8967 - val_loss: 1.9126 - val_accuracy: 0.1250\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 0.1658 - accuracy: 0.9485 - val_loss: 1.9693 - val_accuracy: 0.2500\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.1228 - accuracy: 0.9387 - val_loss: 2.0412 - val_accuracy: 0.2500\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.1340 - accuracy: 0.9652 - val_loss: 2.0673 - val_accuracy: 0.3750\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.1832 - accuracy: 0.9649 - val_loss: 2.6325 - val_accuracy: 0.2500\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 0.0408 - accuracy: 0.9893 - val_loss: 2.8284 - val_accuracy: 0.2500\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.0813 - accuracy: 0.9862 - val_loss: 2.5656 - val_accuracy: 0.2500\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 0.0457 - accuracy: 0.9957 - val_loss: 2.5087 - val_accuracy: 0.2500\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 0.1505 - accuracy: 0.9515 - val_loss: 2.7463 - val_accuracy: 0.2500\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 2.7726 - val_accuracy: 0.3750\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 1s 100ms/step - loss: 0.1465 - accuracy: 0.9454 - val_loss: 2.3162 - val_accuracy: 0.2500\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 0.0768 - accuracy: 0.9939 - val_loss: 2.5761 - val_accuracy: 0.2500\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 3.3996 - val_accuracy: 0.2500\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 2.7867 - val_accuracy: 0.3750\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.1192 - accuracy: 0.9591 - val_loss: 2.5023 - val_accuracy: 0.3750\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.0439 - accuracy: 0.9957 - val_loss: 2.3406 - val_accuracy: 0.3750\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 1s 100ms/step - loss: 0.0989 - accuracy: 0.9577 - val_loss: 2.2088 - val_accuracy: 0.7500\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 1s 105ms/step - loss: 0.1665 - accuracy: 0.9468 - val_loss: 1.4745 - val_accuracy: 0.3750\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 0.2156 - accuracy: 0.9440 - val_loss: 1.8175 - val_accuracy: 0.5000\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 0.0907 - accuracy: 0.9759 - val_loss: 1.2281 - val_accuracy: 0.6250\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 1.1567 - val_accuracy: 0.7500\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.0723 - accuracy: 0.9572 - val_loss: 0.7864 - val_accuracy: 0.8750\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.0481 - accuracy: 0.9755 - val_loss: 0.5675 - val_accuracy: 0.6250\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 1.2435 - val_accuracy: 0.3750\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.0196 - accuracy: 0.9957 - val_loss: 2.1410 - val_accuracy: 0.2500\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.0861 - val_accuracy: 0.6250\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 0.0219 - accuracy: 0.9918 - val_loss: 1.5351 - val_accuracy: 0.3750\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 0.0246 - accuracy: 0.9929 - val_loss: 0.5608 - val_accuracy: 0.7500\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.0235 - accuracy: 0.9893 - val_loss: 0.5374 - val_accuracy: 0.6250\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 0.0428 - accuracy: 0.9777 - val_loss: 0.3237 - val_accuracy: 0.7500\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 0.4410 - accuracy: 0.9632 - val_loss: 0.2642 - val_accuracy: 0.8750\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.8750\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.7500\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 1s 100ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.1990 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 1s 104ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.2268 - val_accuracy: 0.8750\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 1s 100ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.8750\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3191 - val_accuracy: 0.8750\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.8750\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 0.8750\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 1.0000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Test accuracy: 1.0\n",
      "Test loss: 0.006924913264811039\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator\n",
    "    #callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "\n",
    "print(\"Test accuracy: {}\" .format(test_acc))\n",
    "print(\"Test loss: {}\" .format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: test-model-animals.model\\assets\n"
     ]
    }
   ],
   "source": [
    "tfjs_target_dir = \"C:/Users/younis3/Desktop/train_intel/savedmodels/animals\"\n",
    "\n",
    "model.save('test-model-animals.model', tfjs_target_dir)\n",
    "tfjs.converters.save_keras_model(model, tfjs_target_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 840
    }
   ],
   "source": [
    "test_images = []\n",
    "img_path = 'C:/Users/younis3/Desktop/train_intel/my test/1232222.jpg'\n",
    "img = np.array(PIL.Image.open(img_path))\n",
    "img = np.resize(img, (IMG_HEIGHT, IMG_WIDTH, CHANNELS))\n",
    "img = img.astype('float32')\n",
    "img /= 255\n",
    "\n",
    "test_images.append(img)\n",
    "test_images = np.array(test_images)\n",
    "#plt.imshow(test_images)\n",
    "\n",
    "model.predict(test_images)\n",
    "model.predict_classes(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#    def plot_image(i, predictions_array, true_label, img):\n",
    "#     true_label, img = true_label[i], img[i]\n",
    "#     plt.grid(False)\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "\n",
    "#     plt.imshow(img)\n",
    "\n",
    "#     predicted_label = np.argmax(predictions_array)\n",
    "#     if predicted_label == true_label:\n",
    "#         color = 'blue'\n",
    "#     else:\n",
    "#         color = 'red'\n",
    "\n",
    "#     plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "#                             100*np.max(predictions_array),\n",
    "#                             class_names[true_label]),\n",
    "#                             color=color)\n",
    "\n",
    "# def plot_value_array(i, predictions_array, true_label):\n",
    "#     true_label = true_label[i]\n",
    "#     plt.grid(False)\n",
    "#     plt.xticks(range(6))\n",
    "#     plt.yticks([])\n",
    "#     thisplot = plt.bar(range(6), predictions_array, color=\"#777777\")\n",
    "#     plt.ylim([0, 1])\n",
    "#     predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "#     thisplot[predicted_label].set_color('red')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}